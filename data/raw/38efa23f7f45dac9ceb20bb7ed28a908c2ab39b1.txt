Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now
Nous Research, a secretive artificial intelligence startup that has emerged as a leading voice in the open-source AI movement, quietly released Hermes 4 on Monday, a family of large language models that the company claims can match the performance of leading proprietary systems while offering unprecedented user control and minimal content restrictions.
The release represents a significant escalation in the battle between open-source AI advocates and major technology companies over who should control access to advanced artificial intelligence capabilities. Unlike models from OpenAI, Google, or Anthropic, Hermes 4 is designed to respond to nearly any request without the safety guardrails that have become standard in commercial AI systems.
Nous Research presents Hermes 4, our latest line of hybrid reasoning models.https://t.co/E5EW9hBurb
— Nous Research (@NousResearch) August 26, 2025
Hermes 4 builds on our legacy of user-aligned models with expanded test-time compute capabilities.
Special attention was given to making the models creative and interesting to… pic.twitter.com/52VjnvrDWM
“Hermes 4 builds on our legacy of user-aligned models with expanded test-time compute capabilities,” Nous Research announced on X (formerly Twitter). “Special attention was given to making the models creative and interesting to interact with, unencumbered by censorship, and neutrally aligned while maintaining state of the art level math, coding, and reasoning performance for open weight models.”
How Hermes 4’s ‘hybrid reasoning’ mode outperforms ChatGPT and Claude on math benchmarks
Hermes 4 introduces what Nous Research calls “hybrid reasoning,” allowing users to toggle between fast responses and deeper, step-by-step thinking processes. When activated, the models generate their internal reasoning within special <think>
tags before providing a final answer — similar to OpenAI’s o1 reasoning models but with full transparency into the AI’s thought process.
AI Scaling Hits Its Limits
Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:
- Turning energy into a strategic advantage
- Architecting efficient inference for real throughput gains
- Unlocking competitive ROI with sustainable AI systems
Secure your spot to stay ahead: https://bit.ly/4mwGngO
The technical achievement is substantial. In testing, Hermes 4’s largest 405-billion parameter model scored 96.3% on the MATH-500 benchmark in reasoning mode and 81.9% on the challenging AIME’24 mathematics competition — performance that rivals or exceeds many proprietary systems costing millions more to develop.
“The challenge is making thinking traces useful and verifiable without runaway reasoning,” noted AI researcher Rohan Paul on X, highlighting one of the technical breakthroughs in the release.
Perhaps most notably, Hermes 4 achieved the highest score among all tested models on “RefusalBench,” a new benchmark Nous Research created to measure how often AI systems refuse to answer questions. The model scored 57.1% in reasoning mode, significantly outperforming GPT-4o (17.67%) and Claude Sonnet 4 (17%).
Inside DataForge and Atropos: The breakthrough training systems behind Hermes 4’s capabilities
Behind Hermes 4’s capabilities lies a sophisticated training infrastructure that Nous Research has developed over several years. The models were trained using two novel systems: DataForge, a graph-based synthetic data generator, and Atropos, an open-source reinforcement learning framework.
DataForge creates training data through what the company describes as “random walks” through directed graphs, transforming simple pre-training data into complex instruction-following examples. The system can, for instance, take a Wikipedia article and transform it into a rap song, then generate questions and answers based on that transformation.
Atropos, meanwhile, operates like hundreds of specialized training environments where AI models practice specific skills—mathematics, coding, tool use, and creative writing—receiving feedback only when they produce correct solutions. This “rejection sampling” approach ensures that only verified, high-quality responses make it into the training data.
Atropos is Nous' Reinforcement Learning framework
— Tommy (@Shaughnessy119) August 26, 2025
Atropos is an open source reinforcement learning environment by Nous that has hundreds of “gyms” (like math, coding, games, tool‑use, vision) to train and evaluate LLM trajectories via scalable, async RL loops.
In other words… pic.twitter.com/fjxaQKClEZ
“Nous used these environments to generate the dataset for Hermes 4!” explained Tommy Shaughnessy, a venture capitalist at Delphi Ventures who has invested in Nous Research. “All in the dataset contains 3.5 million reasoning samples and 1.6 million non-reasoning samples! Hermes was trained on RL data, not just static datasets of question and answer!”
The training process required 192 Nvidia B200 GPUs and 71,616 GPU hours for the largest model — a significant but not unprecedented computational investment that demonstrates how specialized techniques can compete with the massive scale of tech giants.
Why Nous Research believes AI safety guardrails are ‘annoying as hell’ and hurt innovation
Nous Research has built its reputation on a philosophy that puts user control above corporate content policies. The company’s models are designed to be “steerable,” meaning they can be fine-tuned or prompted to behave in specific ways without the rigid safety constraints that characterize commercial AI systems.
“Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability,” wrote Shaughnessy in a detailed thread analyzing the release. “If its open source but refuses all requests its pointless. Not an issue with Hermes 4.”
Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability.
— Tommy (@Shaughnessy119) August 26, 2025
Hermes 4 70B is at the complete opposite of the spectrum vs OpenAI's open source model. It's also ~4x more open vs ChatGPT 4o!
If its open… pic.twitter.com/q5RpX1oOzo
This approach has made Nous Research popular among AI researchers and developers who want maximum flexibility, but it also places the company at the center of ongoing debates about AI safety and content moderation. While the models can theoretically be used for harmful purposes, Nous Research argues that transparency and user control are preferable to corporate gatekeeping.
The company’s technical report, released alongside the models, provides unprecedented detail about the training process, evaluation results, and even the actual text outputs from benchmark tests. “We believe this report sets a new standard for transparency in benchmarking,” the company stated.
How a small startup with 192 GPUs is competing against Big Tech’s billion-dollar AI budgets
Hermes 4‘s release comes at a pivotal moment in the AI industry. While major technology companies have poured billions into developing increasingly powerful AI systems, a growing open-source movement argues that these capabilities should not be controlled by a handful of corporations.
Recent months have seen significant advances in open-source AI, with models like Meta’s Llama 3.1, DeepSeek’s R1, and Alibaba’s Qwen series achieving performance that rivals proprietary systems. Hermes 4 represents another step in this progression, particularly in the area of reasoning—long considered a strength of closed systems like OpenAI’s o1.
“First up, Nous is a startup with dozens of extremely talented people,” noted Shaughnessy. “They do not have the $100b+ annual capex spend of a hyperscaler nor 1,000’s of employees and despite that they continue to put out innovative models and research at an insane pace.”
The startup, which raised $65 million in funding earlier this year led by Paradigm, has also been developing Psyche Network, a distributed training system that aims to coordinate AI training across internet-connected computers using blockchain technology.
The technical fix that stopped Hermes 4 from thinking in endless loops
One of Hermes 4‘s most significant technical contributions addresses a problem plaguing reasoning models: overly long thinking processes. The researchers found that their smaller 14-billion parameter model would reach maximum context length 60% of the time when reasoning, essentially getting stuck in endless loops of thinking.
Their solution involved a second training stage that teaches models to stop reasoning at exactly 30,000 tokens, reducing overlong generation by 65-79% while maintaining most of the reasoning performance. This “length control” technique could prove valuable for the broader AI research community.
“Smaller models (<14B) tend to overthink when distilled, but larger models don’t,” observed AI researcher Muyu He on X, highlighting insights from the technical report.
However, Hermes 4 still faces limitations common to open-source models. Despite impressive benchmark performance, the models require significant computational resources to run and may not match the ease of use or reliability of commercial AI services for many applications.
Where to try Hermes 4 and what it costs compared to ChatGPT and Claude
Nous Research has made Hermes 4 available through multiple channels, reflecting the open-source philosophy. The model weights are freely downloadable on Hugging Face, while the company also offers API access through its revamped chat interface and partnerships with inference providers like Chutes, Nebius, and Luminal.
“You can try Hermes 4 in the new, revamped Nous Chat UI,” the company announced, highlighting features like parallel interactions and a memory system.
For enterprise users and researchers, the models represent a potentially attractive alternative to paying for API access to proprietary systems, especially for applications requiring high levels of customization or handling of sensitive content.
The bigger picture: What Hermes 4 means for the future of AI development
The release of Hermes 4 represents more than just another AI model launch — it’s a statement about who should control the future of artificial intelligence. In an industry increasingly dominated by a handful of tech giants with virtually unlimited resources, Nous Research has demonstrated that innovation can still come from unexpected places.
The company’s approach raises fundamental questions about the trade-offs between safety and capability, between corporate control and user freedom. While major technology companies argue that careful content moderation and safety guardrails are essential for responsible AI deployment, Nous Research contends that transparency and user agency are more important than corporate-imposed restrictions.
Whether this philosophy will ultimately prove beneficial or problematic remains to be seen. But one thing is certain: Hermes 4 has shown that the future of AI won’t be determined solely by the companies with the deepest pockets.
In a field where yesterday’s impossibilities become tomorrow’s commodities, Nous Research just proved that the only thing more dangerous than an AI that says no might be one that’s willing to say yes.