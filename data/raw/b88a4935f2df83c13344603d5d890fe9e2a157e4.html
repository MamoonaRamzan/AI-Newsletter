<!DOCTYPE html><html
lang=en-US><head><meta
charset="UTF-8"><title>
LLM System Design and Model Selection – O’Reilly</title><meta
name='robots' content='max-image-preview:large'><style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style> <script>/*<![CDATA[*/window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/16.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/16.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/www.oreilly.com\/radar\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.8.2"}};
/*! This file is auto-generated */
!function(s,n){var o,i,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),a=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===a[t]})}function u(e,t){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);for(var n=e.getImageData(16,16,1,1),a=0;a<n.data.length;a++)if(0!==n.data[a])return!1;return!0}function f(e,t,n,a){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\udde8\ud83c\uddf6","\ud83c\udde8\u200b\ud83c\uddf6")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!a(e,"\ud83e\udedf")}return!1}function g(e,t,n,a){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):s.createElement("canvas"),o=r.getContext("2d",{willReadFrequently:!0}),i=(o.textBaseline="top",o.font="600 32px Arial",{});return e.forEach(function(e){i[e]=t(o,e,n,a)}),i}function t(e){var t=s.createElement("script");t.src=e,t.defer=!0,s.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",i=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){s.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+g.toString()+"("+[JSON.stringify(i),f.toString(),p.toString(),u.toString()].join(",")+"));",a=new Blob([e],{type:"text/javascript"}),r=new Worker(URL.createObjectURL(a),{name:"wpTestEmojiSupports"});return void(r.onmessage=function(e){c(n=e.data),r.terminate(),t(n)})}catch(e){}c(n=g(i,f,p,u))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);/*]]>*/</script> <style id=wp-emoji-styles-inline-css>img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}</style><link
rel=stylesheet href=https://www.oreilly.com/radar/wp-content/cache/minify/3/a5ff7.css media=all><style id=classic-theme-styles-inline-css>/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}</style><style id=global-styles-inline-css>/*<![CDATA[*/:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}/*]]>*/</style><link
rel=stylesheet href=https://www.oreilly.com/radar/wp-content/cache/minify/3/669c0.css media=all> <script src=https://www.oreilly.com/radar/wp-content/cache/minify/3/818c0.js></script> <link
rel=canonical href=https://www.oreilly.com/radar/llm-system-design-and-model-selection/ ><link
rel=shortlink href='https://www.oreilly.com/radar/?p=17336'><link
rel=alternate type=application/rss+xml title="Podcast RSS feed" href=https://www.oreilly.com/radar/feed/podcast><link
rel=icon href=https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/04/cropped-favicon_512x512-160x160.png sizes=32x32><link
rel=icon href=https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/04/cropped-favicon_512x512-300x300.png sizes=192x192><link
rel=apple-touch-icon href=https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/04/cropped-favicon_512x512-300x300.png><meta
name="msapplication-TileImage" content="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/04/cropped-favicon_512x512-300x300.png"><meta
http-equiv="X-UA-Compatible" content="IE=edge"><meta
name="viewport" content="width=device-width, initial-scale=1"><meta
name="language_name" content="English"><meta
name="native_language_name" content="English"><meta
name="format-detection" content="telephone=no"><link
rel=icon type=image/png href=//www.oreilly.com/favicon.ico><!--[if lte IE 9]> <script>'article aside footer header main nav section time'.replace(/\w+/g,function(n){document.createElement(n)})</script> <![endif]--><!--[if IE 9]><style>#menu-toggle:checked ~ .mobile-nav { display:block; }
  .mobile-nav { display: none; }</style><![endif]--><meta
property="twitter:card" content="summary_large_image"><meta
property="twitter:site" content="@OReillyMedia"><meta
property="twitter:title" content="LLM System Design and Model Selection"><meta
property="twitter:description" content="Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning"><meta
property="twitter:url" content="https://www.oreilly.com/radar/llm-system-design-and-model-selection"><meta
property="twitter:image" content="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/anatomy-1751201_crop-355c0e36608a04c85c14cdb0023bc1e3-1.jpg"><meta
property="og:type" content="article"><meta
property="og:site_name" content="O’Reilly Media"><meta
property="og:title" content="LLM System Design and Model Selection"><meta
property="og:description" content="Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning"><meta
property="og:url" content="https://www.oreilly.com/radar/llm-system-design-and-model-selection/"><meta
property="og:image" content="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/anatomy-1751201_crop-355c0e36608a04c85c14cdb0023bc1e3-1.jpg"><meta
name="description" content="Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning"><meta
name="author" content="Louis-François Bouchard, Louie Peters"><meta
name="description:site" content="Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning"><meta
property="article:published_time" content="2025-08-26T10:07:35+00:00"><meta
name="article:author" content="Louis-François Bouchard, Louie Peters"><meta
name="date" content="2025-08-26"><meta
name="thumbnail" content="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/anatomy-1751201_crop-355c0e36608a04c85c14cdb0023bc1e3-1.jpg"><meta
name="graphic_medium" content="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/anatomy-1751201_crop-355c0e36608a04c85c14cdb0023bc1e3-1.jpg"><meta
name="oreilly:content_type" content="text"> <script>loggedInObject = new Object();
  var dataLayer = window.dataLayer || [];

  //Check for O'Reilly Unified logged-in status
  if (document.cookie.split(';').filter(function(item) {
    return item.indexOf('orm-jwt=') >= 0;
  }).length) {
    loggedInObject.loggedIn = 'yes';
    dataLayer.push(loggedInObject);
  }</script> <script>dataLayer = [{"content.author":"Louis-François Bouchard, Louie Peters","content.formatType":"article","content.free":"yes","content.identifier":"none","content.parentTopic":"AI & ML","content.publisher":"O'Reilly Media Inc.","content.releaseDate":"2025-08-26","content.subTopic":"none","content.subdirectory":"radar","content.title":"LLM System Design and Model Selection","product.identifier":"none","product.title":"none","product.type":"none"}];</script>  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5P4V6Z');</script> <link
rel=preconnect href=https://dev.visualwebsiteoptimizer.com> <script id=vwoCode>window._vwo_code || (function() {
var account_id=27087,
version=2.1,
settings_tolerance=2000,
hide_element='body',
hide_element_style = 'opacity:0 !important;filter:alpha(opacity=0) !important;background:none !important',
/* DO NOT EDIT BELOW THIS LINE */
f=false,w=window,d=document,v=d.querySelector('#vwoCode'),cK='_vwo_'+account_id+'_settings',cc={};try{var c=JSON.parse(localStorage.getItem('_vwo_'+account_id+'_config'));cc=c&&typeof c==='object'?c:{}}catch(e){}var stT=cc.stT==='session'?w.sessionStorage:w.localStorage;code={use_existing_jquery:function(){return typeof use_existing_jquery!=='undefined'?use_existing_jquery:undefined},library_tolerance:function(){return typeof library_tolerance!=='undefined'?library_tolerance:undefined},settings_tolerance:function(){return cc.sT||settings_tolerance},hide_element_style:function(){return'{'+(cc.hES||hide_element_style)+'}'},hide_element:function(){if(performance.getEntriesByName('first-contentful-paint')[0]){return''}return typeof cc.hE==='string'?cc.hE:hide_element},getVersion:function(){return version},finish:function(e){if(!f){f=true;var t=d.getElementById('_vis_opt_path_hides');if(t)t.parentNode.removeChild(t);if(e)(new Image).src='https://dev.visualwebsiteoptimizer.com/ee.gif?a='+account_id+e}},finished:function(){return f},addScript:function(e){var t=d.createElement('script');t.type='text/javascript';if(e.src){t.src=e.src}else{t.text=e.text}d.getElementsByTagName('head')[0].appendChild(t)},load:function(e,t){var i=this.getSettings(),n=d.createElement('script'),r=this;t=t||{};if(i){n.textContent=i;d.getElementsByTagName('head')[0].appendChild(n);if(!w.VWO||VWO.caE){stT.removeItem(cK);r.load(e)}}else{var o=new XMLHttpRequest;o.open('GET',e,true);o.withCredentials=!t.dSC;o.responseType=t.responseType||'text';o.onload=function(){if(t.onloadCb){return t.onloadCb(o,e)}if(o.status===200){_vwo_code.addScript({text:o.responseText})}else{_vwo_code.finish('&e=loading_failure:'+e)}};o.onerror=function(){if(t.onerrorCb){return t.onerrorCb(e)}_vwo_code.finish('&e=loading_failure:'+e)};o.send()}},getSettings:function(){try{var e=stT.getItem(cK);if(!e){return}e=JSON.parse(e);if(Date.now()>e.e){stT.removeItem(cK);return}return e.s}catch(e){return}},init:function(){if(d.URL.indexOf('__vwo_disable__')>-1)return;var e=this.settings_tolerance();w._vwo_settings_timer=setTimeout(function(){_vwo_code.finish();stT.removeItem(cK)},e);var t;if(this.hide_element()!=='body'){t=d.createElement('style');var i=this.hide_element(),n=i?i+this.hide_element_style():'',r=d.getElementsByTagName('head')[0];t.setAttribute('id','_vis_opt_path_hides');v&&t.setAttribute('nonce',v.nonce);t.setAttribute('type','text/css');if(t.styleSheet)t.styleSheet.cssText=n;else t.appendChild(d.createTextNode(n));r.appendChild(t)}else{t=d.getElementsByTagName('head')[0];var n=d.createElement('div');n.style.cssText='z-index: 2147483647 !important;position: fixed !important;left: 0 !important;top: 0 !important;width: 100% !important;height: 100% !important;background: white !important;';n.setAttribute('id','_vis_opt_path_hides');n.classList.add('_vis_hide_layer');t.parentNode.insertBefore(n,t.nextSibling)}var o='https://dev.visualwebsiteoptimizer.com/j.php?a='+account_id+'&u='+encodeURIComponent(d.URL)+'&vn='+version;if(w.location.search.indexOf('_vwo_xhr')!==-1){this.addScript({src:o})}else{this.load(o+'&x=true')}}};w._vwo_code=code;code.init();})();</script>  <script type=application/ld+json>{
    "@context": "https://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
        {
            "@type": "ListItem",
            "position": 1,
            "name": "O'Reilly",
            "item": "https://www.oreilly.com/"
        },
        {
            "@type": "ListItem",
            "position": 2,
            "name": "Radar",
            "item": "https://www.oreilly.com/radar/"
        },
        {
            "@type": "ListItem",
            "position": 3,
            "name": "LLM System Design and Model Selection",
            "item": "https://www.oreilly.com/radar/llm-system-design-and-model-selection/"
        }
    ]
}</script> </head><body
class="wp-singular post-template-default single single-post postid-17336 single-format-standard wp-theme-signal multisite-radar"><noscript><iframe
src="https://www.googletagmanager.com/ns.html?id=GTM-5P4V6Z" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><a
class=skipToMain id=skipToMain href=#maincontent>Skip to main content</a><header
role=banner><div
class=content><nav
role=navigation aria-label="site sections"><ul
class=marketingMenu>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/teams.html>For Enterprise</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/government.html>For Government</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/academic.html>For Higher Ed</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/individuals.html>For Individuals</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/content-marketing-solutions.html>For Content Marketing</a></li></ul><div
class=primaryMenu>
<a
href=https://www.oreilly.com class=logo title="home page">
<img
src=https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg
srcset="https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red_@2x.png 2x"
alt="O'Reilly home">
</a><ul
id=menuList class="menuList mobileHidden {cs.var.menulist-class}">
<li
class=menuList-itemsLeft><ul>
<li
class="menuList-item mobileOnly"><a
href=https://www.oreilly.com/online-learning/teams.html>For Enterprise</a></li>
<li
class="menuList-item mobileOnly"><a
href=https://www.oreilly.com/online-learning/government.html>For Government</a></li>
<li
class="menuList-item mobileOnly"><a
href=https://www.oreilly.com/online-learning/academic.html>For Higher Ed</a></li>
<li
class="menuList-item mobileOnly"><a
href=https://www.oreilly.com/online-learning/individuals.html>For Individuals</a></li>
<li
class="menuList-item mobileOnly"><a
href=https://www.oreilly.com/content-marketing-solutions.html>For Content Marketing</a></li>
<li
class="menuList-item menuList-itemWithSub"><a
href=/search/skills>Explore Skills</a><ul
class="menuList-subList mobileHidden" id=skillsMenu></ul>
</li>
<li
class="menuList-item menuList-itemWithSub"><a
href=https://www.oreilly.com/online-learning/features.html>Features</a><ul
class=menuList-subList>
<li
class="menuList-subItem menuList-extra"><a
href=https://www.oreilly.com/online-learning/features.html>All Features</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/ai-academy.html>AI Academy</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/courses.html>Courses</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/feature-certification.html>Certifications</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/intro-interactive-learning.html>Interactive Learning</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/live-events.html>Live Events</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/feature-answers.html>Answers</a></li>
<li
class=menuList-subItem><a
href=https://www.oreilly.com/online-learning/insights-dashboard.html>Insights Reporting</a></li></ul>
</li>
<li
class=menuList-item><a
href=https://www.oreilly.com/radar/ aria-current=page>Radar Blog</a></li>
<li
class=menuList-item><a
href=https://www.oreilly.com/live/ >Buy Courses</a></li>
<li
class="menuList-item menuList-item-search" id=nav-search><form
id=js-searchForm class=searchForm action=https://www.oreilly.com/search/ ><input
id=search type=search name=query placeholder="Explore our content" autocomplete=off required><button
id=js-searchCloseButton class=navSearchCloseButton>Close</button></form>
<button
id=js-searchButton class=navSearchButton>Search</button>
</li></ul>
</li>
<li
class=menuList-itemsRight><ul>
<li
class="menuList-item menuList-plans"><a
href=https://www.oreilly.com/online-learning/pricing.html>Plans</a></li>
<li
class="menuList-item menuList-signIn"><a
id=nav-signIn href=https://www.oreilly.com/member/login/ >Sign In</a></li>
<li
class="menuList-item menuList-tryNow"><a
id=nav-tryNow class=menuList-cta href=https://www.oreilly.com/online-learning/try-now.html>Try Now</a></li>
<li
class="menuList-item menuList-platform"><a
id=nav-platform class=menuList-cta href=https://www.oreilly.com/member/login/ >O&rsquo;Reilly Platform</a></li></ul>
</li></ul><button
id=mobileNavButton class="mobileNavButton mobileNavButton--collapse" type=button aria-expanded=false aria-controls=menuList>
<span
class=mobileNavButton-box>
<span
class=mobileNavButton-inner></span>
</span>
</button></div></nav></div></header><div
class=headerBranding><div
class=content>
<a
class=hero-radar href=/radar/ title=Radar></a>
<button
id=themeToggle class=themeToggle aria-pressed=false>
<span
class=srOnly>Toggle dark mode</span>
<span
class=dark></span>
<span
class=light></span>
</button></div></div><main
role=main id=maincontent> <script type=application/ld+json>{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "@id": "https://www.oreilly.com/radar/llm-system-design-and-model-selection/#BlogPosting",
  "mainEntityOfPage": "https://www.oreilly.com/radar/llm-system-design-and-model-selection/",
  "headline": "LLM System Design and Model Selection",
  "description": "Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning strengths to cost efficiency to code generation. This competition creates strong incentives for AI labs to carve out a niche and gives new startups room to emerge, resulting in a fragmented landscape …",
  "image": {
    "@type": "ImageObject",
    "url": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/anatomy-1751201_crop-355c0e36608a04c85c14cdb0023bc1e3-1.jpg"
  },
  "author": [
    {"@type": "Person", "name": "Louis-François Bouchard", "url": "https://www.oreilly.com/people/louis-francois-bouchard/"},
    {"@type": "Person", "name": "Louie Peters", "url": "https://www.oreilly.com/people/louie-peters/"}  ],
  "publisher": {
    "@type": "Organization",
    "name": "O'Reilly Media",
    "url": "https://www.oreilly.com/",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg",
      "width": 200,
      "height": 50
    }
  },
  "datePublished": "2025-08-26",
  "dateModified": "2025-08-26",
  "wordCount": "4354",
  "timeRequired": "PT22M",
  "keywords": ["Research"],
  "genre": ["AI &amp; ML"],
  "isPartOf": {
    "@type": "Blog",
    "name": "O'Reilly Radar",
    "url": "https://www.oreilly.com/radar/"
  },
  "potentialAction": {
    "@type": "ViewAction",
    "target": "https://www.oreilly.com/radar/llm-system-design-and-model-selection/",
    "name": "Read Full Article"
  }
}</script> <div
class=pageLayout><div
class=sidebar id=right-rail><div
class="module open"><form
id=searchForm class=search role=search method=get action=https://www.oreilly.com/radar/ >
<input
type=search name=s placeholder=Search value></form><div
class=topics>
<a
href=/radar/topics/ai-ml/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label="ai & ml">AI &amp; ML</a>
<a
href=/radar/topics/business/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label=business>Business</a>
<a
href=/radar/topics/data/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label=data>Data</a>
<a
href=/radar/topics/innovation-and-disruption/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label=innovation>Innovation</a>
<a
href=/radar/tag/research/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label=research>Research</a>
<a
href=/radar/topics/security/ class=topicChip data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=topic data-ga-label=security>Security</a></div></div><div
class="module mobileMove"><h2>Buy courses</h2><p>Get expert-led live training on exactly what you want to learn.</p><div
class=upcomingEvents><a
href="https://www.oreilly.com/live/event-detail.csp?series=0636920327219&event=0642572180898" data-ga-event-name=eventTracker data-ga-category=radar data-ga-event="live event" data-ga-label="software architecture styles"><span
class=date><span
class=month>Sep</span><span
class=day>2</span></span><span
class=text><span
class=title>Software Architecture Styles</span></span></a><a
href="https://www.oreilly.com/live/event-detail.csp?series=0636920059654&event=0642572207694" data-ga-event-name=eventTracker data-ga-category=radar data-ga-event="live event" data-ga-label="hands-on software design"><span
class=date><span
class=month>Sep</span><span
class=day>2</span></span><span
class=text><span
class=title>Hands-on Software Design</span></span></a><a
href="https://www.oreilly.com/live/event-detail.csp?series=0642572191870&event=0642572191863" data-ga-event-name=eventTracker data-ga-category=radar data-ga-event="live event" data-ga-label="vibing with statistics"><span
class=date><span
class=month>Sep</span><span
class=day>2</span></span><span
class=text><span
class=title>Vibing with Statistics</span></span></a></div>
<a
href=https://www.oreilly.com/live/ class=ctaLink data-ga-event-name=eventTracker data-ga-category=radar data-ga-event="live event" data-ga-label="see all">See all</a></div><div
class="module mobileMove"><h2>Try the O’Reilly learning platform</h2><p>With the O’Reilly learning platform, you get the resources and guidance to keep your skills sharp and stay ahead. Try it free for 10 days.</p><a
href=https://learning.oreilly.com/start-trial/ class=ctaLink data-ga-event-name=eventTracker data-ga-category=radar data-ga-event=promo data-ga-label="start trial">Start trial</a></div><div
class="module mobileMove"><form
id=marketingCloudForm class=mc-form action=https://cl.exct.net/DEManager.aspx name=subscribeForm
method=post><h2>Get the Radar Trends newsletter</h2><input
type=hidden name=_clientID value=7200351>
<input
type=hidden name=_deExternalKey value=3559B084-4962-47D6-AD05-DAA2DE51CF45>
<input
type=hidden name=_action value=add>
<input
type=hidden name=_returnXML value=0>
<input
type=hidden name=_successURL value="https://www.oreilly.com/radar/?success=true">
<input
type=hidden name=_errorURL value="https://www.oreilly.com/radar/?error=true">
<input
type=hidden name=NewsletterTopic value=RadarTrends>
<input
type=hidden name=Marketing_Context value="email signup at https://www.oreilly.com/emails/newsletters/"><div
id=marketingCloudForm-errorMessage class=mc-form-errorMessage></div><div
class=mc-form-group><div
class=mc-form-item><label
for=emailaddress>Your email</label><input
type=email name=emailaddress
id=emailaddress data-text="email address" autocomplete=email aria-required=true></div><div
class=mc-form-item>
<label
for=country>Country</label>
<select
name=country id=country data-text=country autocomplete=country-name aria-required=true><option
value>- Select country -</option><option
value="United States">United States</option><option
value=Afghanistan>Afghanistan</option><option
value=Albania>Albania</option><option
value=Algeria>Algeria</option><option
value=Andorra>Andorra</option><option
value=Angola>Angola</option><option
value="Antigua and Barbuda">Antigua and Barbuda</option><option
value=Argentina>Argentina</option><option
value=Armenia>Armenia</option><option
value=Aruba>Aruba</option><option
value=Australia>Australia</option><option
value=Austria>Austria</option><option
value=Azerbaijan>Azerbaijan</option><option
value=Bahamas>The Bahamas</option><option
value=Bahrain>Bahrain</option><option
value=Bangladesh>Bangladesh</option><option
value=Barbados>Barbados</option><option
value=Belarus>Belarus</option><option
value=Belgium>Belgium</option><option
value=Belize>Belize</option><option
value=Benin>Benin</option><option
value=Bermuda>Bermuda</option><option
value=Bhutan>Bhutan</option><option
value="Bolivia, Plurinational State of">Bolivia</option><option
value="Bosnia and Herzegovina">Bosnia and Herzegovina</option><option
value=Botswana>Botswana</option><option
value=Brazil>Brazil</option><option
value="Brunei Darussalam">Brunei</option><option
value=Bulgaria>Bulgaria</option><option
value="Burkina Faso">Burkina Faso</option><option
value=Burundi>Burundi</option><option
value=Cambodia>Cambodia</option><option
value=Cameroon>Cameroon</option><option
value=Canada>Canada</option><option
value="Cape Verde">Cape Verde</option><option
value="Central African Republic">Central African Republic</option><option
value=Chad>Chad</option><option
value=Chile>Chile</option><option
value=China>People's Republic of China</option><option
value=Colombia>Colombia</option><option
value=Comoros>Comoros</option><option
value=Congo>Congo, Republic of the</option><option
value="Congo, the Democratic Republic of the">Congo, Democratic Republic of the</option><option
value="Cook Islands">Cook Islands</option><option
value="Costa Rica">Costa Rica</option><option
value="Cote d'Ivoire">C&ocirc;te d'Ivoire (Ivory Coast)</option><option
value=Croatia>Croatia</option><option
value=Cuba>Cuba</option><option
value=Cyprus>Cyprus</option><option
value="Czech Republic">Czechia</option><option
value=Denmark>Denmark</option><option
value=Djibouti>Djibouti</option><option
value=Dominica>Dominica</option><option
value="Dominican Republic">Dominican Republic</option><option
value=Ecuador>Ecuador</option><option
value=Egypt>Egypt</option><option
value="El Salvador">El Salvador</option><option
value="Equatorial Guinea">Equatorial Guinea</option><option
value=Eritrea>Eritrea</option><option
value=Estonia>Estonia</option><option
value=Swaziland>Eswatini (formerly Swaziland)</option><option
value=Ethiopia>Ethiopia</option><option
value="Federated States of Micronesia">Federated States of Micronesia</option><option
value=Fiji>Fiji</option><option
value=Finland>Finland</option><option
value=France>France</option><option
value=Gabon>Gabon</option><option
value=Gambia>The Gambia</option><option
value=Georgia>Georgia</option><option
value=Germany>Germany</option><option
value=Ghana>Ghana</option><option
value=Greece>Greece</option><option
value=Grenada>Grenada</option><option
value=Guatemala>Guatemala</option><option
value=Guinea>Guinea</option><option
value=Guinea-Bissau>Guinea-Bissau</option><option
value=Guyana>Guyana</option><option
value=Haiti>Haiti</option><option
value=Honduras>Honduras</option><option
value=Hungary>Hungary</option><option
value=Iceland>Iceland</option><option
value=India>India</option><option
value=Indonesia>Indonesia</option><option
value="Iran, Islamic Republic of">Iran</option><option
value=Iraq>Iraq</option><option
value=Ireland>Ireland</option><option
value=Israel>Israel</option><option
value=Italy>Italy</option><option
value=Jamaica>Jamaica</option><option
value=Japan>Japan</option><option
value=Jordan>Jordan</option><option
value=Kazakhstan>Kazakhstan</option><option
value=Kenya>Kenya</option><option
value=Kiribati>Kiribati</option><option
value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option><option
value="Korea, Republic of">Korea, Republic of</option><option
value=Kuwait>Kuwait</option><option
value=Kyrgyzstan>Kyrgyzstan</option><option
value="Lao People's Democratic Republic">Laos</option><option
value=Latvia>Latvia</option><option
value=Lebanon>Lebanon</option><option
value=Lesotho>Lesotho</option><option
value=Liberia>Liberia</option><option
value="Libyan Arab Jamahiriya">Libya</option><option
value=Liechtenstein>Liechtenstein</option><option
value=Lithuania>Lithuania</option><option
value=Luxembourg>Luxembourg</option><option
value="Macedonia, the former Yugoslav Republic of">Macedonia, Republic of</option><option
value=Madagascar>Madagascar</option><option
value=Malawi>Malawi</option><option
value=Malaysia>Malaysia</option><option
value=Maldives>Maldives</option><option
value=Mali>Mali</option><option
value=Malta>Malta</option><option
value=Mauritania>Mauritania</option><option
value=Mauritius>Mauritius</option><option
value=Mexico>Mexico</option><option
value="Moldova, Republic of">Moldova</option><option
value=Monaco>Monaco</option><option
value=Mongolia>Mongolia</option><option
value=Montenegro>Montenegro</option><option
value=Morocco>Morocco</option><option
value=Mozambique>Mozambique</option><option
value=Myanmar>Myanmar</option><option
value=Namibia>Namibia</option><option
value=Nauru>Nauru</option><option
value=Nepal>Nepal</option><option
value=Netherlands>Netherlands</option><option
value="New Zealand">New Zealand</option><option
value=Nicaragua>Nicaragua</option><option
value=Niger>Niger</option><option
value=Nigeria>Nigeria</option><option
value=Niue>Niue</option><option
value=Norway>Norway</option><option
value=Oman>Oman</option><option
value=Pakistan>Pakistan</option><option
value="Palestinian Territory, Occupied">Palestine, State of</option><option
value=Panama>Panama</option><option
value="Papua New Guinea">Papua New Guinea</option><option
value=Paraguay>Paraguay</option><option
value=Peru>Peru</option><option
value=Philippines>Philippines</option><option
value=Poland>Poland</option><option
value=Portugal>Portugal</option><option
value=Qatar>Qatar</option><option
value=Romania>Romania</option><option
value="Russian Federation">Russia</option><option
value=Rwanda>Rwanda</option><option
value="Saint Kitts and Nevis">Saint Kitts and Nevis</option><option
value="Saint Lucia">Saint Lucia</option><option
value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option><option
value=Samoa>Samoa</option><option
value="San Marino">San Marino</option><option
value="Sao Tome and Principe">S&atilde;o Tom&eacute; and Pr&iacute;ncipe</option><option
value="Saudi Arabia">Saudi Arabia</option><option
value=Senegal>Senegal</option><option
value=Serbia>Serbia</option><option
value=Seychelles>Seychelles</option><option
value="Sierra Leone">Sierra Leone</option><option
value=Singapore>Singapore</option><option
value=Slovakia>Slovakia</option><option
value=Slovenia>Slovenia</option><option
value="Solomon Islands">Solomon Islands</option><option
value=Somalia>Somalia</option><option
value="South Africa">South Africa</option><option
value="South Sudan">South Sudan</option><option
value=Spain>Spain</option><option
value="Sri Lanka">Sri Lanka</option><option
value=Sudan>Sudan</option><option
value=Suriname>Suriname</option><option
value=Sweden>Sweden</option><option
value=Switzerland>Switzerland</option><option
value="Syrian Arab Republic">Syria</option><option
value="Chinese Taipei">Taiwan</option><option
value=Tajikistan>Tajikistan</option><option
value="Tanzania, United Republic of">Tanzania</option><option
value=Thailand>Thailand</option><option
value=Timor-Leste>Timor-Leste (East Timor)</option><option
value=Togo>Togo</option><option
value=Tonga>Tonga</option><option
value="Trinidad and Tobago">Trinidad and Tobago</option><option
value=Tunisia>Tunisia</option><option
value=Turkey>Turkey</option><option
value=Turkmenistan>Turkmenistan</option><option
value=Tuvalu>Tuvalu</option><option
value=Uganda>Uganda</option><option
value=Ukraine>Ukraine</option><option
value="United Arab Emirates">United Arab Emirates</option><option
value="United Kingdom">United Kingdom</option><option
value="United States">United States</option><option
value=Uruguay>Uruguay</option><option
value=Uzbekistan>Uzbekistan</option><option
value=Vanuatu>Vanuatu</option><option
value="Holy See (Vatican City State)">Vatican City</option><option
value="Venezuela, Bolivarian Republic of">Venezuela</option><option
value="Viet Nam">Vietnam</option><option
value=Yemen>Yemen</option><option
value=Zambia>Zambia</option><option
value=Zimbabwe>Zimbabwe</option>
</select></div><div
class=mc-form-item><div
class="consentGroup hidden" id=consentGroup></div></div><div
class=mc-form-item><button
type=submit onclick="return verifMCForm();">Subscribe</button></div><div
class=mc-form-item><p
class=privacy>Please read our <a
href=http://oreilly.com/oreilly/privacy.html target=_blank>privacy policy</a>.</p></div></div></form><div
id=marketingCloudForm-thankyou class="marketingCloudForm-thankyou hidden"><h2>Thank you for subscribing to the O’Reilly Radar Trends to Watch newsletter.</h2></div> <script src=https://cdn.oreillystatic.com/assets/js/marketingCloudForm-20250502.js></script> <script src=https://www.oreilly.com/radar/wp-content/cache/minify/3/52453.js></script> </div></div><div
class=blogPost><div
class=pageHeader><p
class=breadcrumbs>
<a
href=https://www.oreilly.com/radar>Radar</a>
&gt; <a
href=https://www.oreilly.com/radar/topics/ >Topics</a>
&gt; <a
href=https://www.oreilly.com/radar/topics/ai-ml/ >AI & ML</a></p><div
class=pageHeaderContent><div
class=title><h1>LLM System Design and Model Selection</h1><div
class=description><p></p></div></div><div
class=radar-post-page-meta><figure
class=authorPhotos>
<img
class=people-author-image src=https://www.oreilly.com/radar/wp-content/uploads/sites/4/2025/08/LouisFrancoisBouchard-150x150.png alt="Louis-François Bouchard with a grey background"><img
class=people-author-image src=https://www.oreilly.com/radar/wp-content/uploads/sites/4/2025/08/LouiePeters-150x150.png alt="Photo of Louie Peters on a beach"></figure><p
class=text>
<span
class=radar-post-page-author>
By <a
href=https://www.oreilly.com/people/louis-francois-bouchard/ >Louis-François Bouchard</a> and <a
href=https://www.oreilly.com/people/louie-peters/ >Louie Peters</a>  </span><span
class=radar-post-page-date>August 26, 2025 &bull; 22 minute read</span></p></div><div
class=radar-post-page-actions>
<button
class=share id=share><span
class=icon></span><span
class=text>Share</span></button><div
class=shareOverlay id=shareOverlay><div
class=shareItems id=shareItems>
<button
class=close><span
class=reader>Close</span></button><a
href="https://www.linkedin.com/feed/?shareActive&mini=true&text=O%E2%80%99Reilly%20-%20LLM%20System%20Design%20and%20Model%20Selection%20with%20Louis-Fran%C3%A7ois%20Bouchard%20and%20Louie%20Peters%20-%20https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fllm-system-design-and-model-selection%2F" class=linkedin rel="noopener nofollow noreferrer" aria-label="Share on LinkedIn" target=_blank><span
class=reader>LinkedIn</span></a><a
href="https://x.com/intent/tweet?original_referer=https%3A%2F%2Fwww.oreilly.com%2F&text=O%E2%80%99Reilly%20-%20LLM%20System%20Design%20and%20Model%20Selection%20with%20Louis-Fran%C3%A7ois%20Bouchard%20and%20Louie%20Peters%20-%20https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fllm-system-design-and-model-selection%2F" class=x rel="noopener nofollow noreferrer" aria-label="Share on X" target=_blank><span
class=reader>X</span></a><a
href="https://www.facebook.com/sharer/sharer.php?quote=O%E2%80%99Reilly%20-%20LLM%20System%20Design%20and%20Model%20Selection%20with%20Louis-Fran%C3%A7ois%20Bouchard%20and%20Louie%20Peters%20-%20https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fllm-system-design-and-model-selection%2F" class=facebook rel="noopener nofollow noreferrer" aria-label="Share on Facebook" target=_blank><span
class=reader>Facebook</span></a><a
href="https://threads.net/intent/post?text=O%E2%80%99Reilly%20-%20LLM%20System%20Design%20and%20Model%20Selection%20with%20Louis-Fran%C3%A7ois%20Bouchard%20and%20Louie%20Peters%20-%20https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fllm-system-design-and-model-selection%2F" class=threads rel="noopener nofollow noreferrer" aria-label="Share on Threads" target=_blank><span
class=reader>Threads</span></a><a
href="https://bsky.app/intent/compose?text=O%E2%80%99Reilly%20-%20LLM%20System%20Design%20and%20Model%20Selection%20with%20Louis-Fran%C3%A7ois%20Bouchard%20and%20Louie%20Peters%20-%20https%3A%2F%2Fwww.oreilly.com%2Fradar%2Fllm-system-design-and-model-selection%2F" class=bluesky rel="noopener nofollow noreferrer" aria-label="Share on Bluesky" target=_blank><span
class=reader>Bluesky</span></a></div></div> <script>// Show share overlay when share button is clicked
  document.getElementById('share').addEventListener('click', (e) => {
    shareItems.classList.remove('hidden');
    shareOverlay.classList.add('over');
    document.querySelector('body').classList.add('fixed');
  });

  function hideShareOverlay() {
    shareOverlay.classList.remove('over');
    shareItems.classList.add('hidden');
    document.querySelector('body').classList.remove('fixed');
  }

  const shareItemsClose = shareItems.querySelector('.close');
  shareItemsClose.addEventListener('click', (e) => {
    hideShareOverlay();
  });

  shareOverlay.addEventListener('click', (e) => {
    hideShareOverlay();
  });

  shareItems.addEventListener('click', (e) => {
    e.stopPropagation();
  });</script> </div></div></div><section
class="postContent "><div
class=postContent-content id=postContent-content><p>Choosing the right LLM has become a full-time job. New models appear almost daily, each offering different capabilities, prices, and quirks, from reasoning strengths to cost efficiency to code generation. This competition creates strong incentives for AI labs to carve out a niche and gives new startups room to emerge, resulting in a fragmented landscape where one model may excel at reasoning, another at code, and a third at cost efficiency.</p><p>AI, in one sense, is getting cheaper faster than any previous technology, at least per <em>unit of intelligence</em>. For example, input tokens for Gemini 2.5 Flash-Lite are approximately 600 times cheaper than what OpenAI’s GPT-3 (davinci-002) cost in August 2022, while outperforming it on every metric. At the same time, access to frontier capabilities is also becoming more expensive than ever. The reason is simple: we can now pay directly for more capability, which has led to the rise of $300+ per month Pro subscription tiers.</p><p>Today, any developer can run capable open-weight models locally for negligible marginal cost using tools like Ollama. At the same time, enterprise systems can experience sharp cost increases, depending on the model size (number of parameters, such as 3 billion, 70 billion, or even in the trillions), the number of internal processing steps, and the volume of input data. For developers, these are central system design choices that directly affect feasibility and cost structure. For end users, this complexity explains why a basic subscription differs so much from a premium plan with higher limits on advanced models.</p><p>The choices you make in these broader development decisions also determine which LLM and inference settings are optimal for your use case.</p><p>At Towards AI, we work across the LLM stack, building applications, designing enterprise systems, and offering online courses (<a
href=https://www.oreilly.com/videos/building-and-operating/019283645221/ target=_blank rel="noreferrer noopener">including one on O’Reilly</a>), custom corporate training, and LLM development consultancy. In our experience, model selection and system design have become central to getting meaningful results from these tools. Much of that, in turn, depends on where today’s models are gaining their capabilities. While scale still plays a role, recent progress has come from a broader mix of factors, including training-data quality, post-training methods, and especially how models are used at inference time.</p><h2 class="wp-block-heading"><strong>The Shifting Foundations of Model Capability</strong></h2><p>While early gains in LLM performance tracked closely with increases in pretraining compute, larger datasets, bigger models, and more training steps, this approach now yields diminishing returns.</p><p>Recent improvements come from a broader mix of strategies. Pretraining-data quality has become just as important as quantity, with better filtering and AI-generated synthetic data contributing to stronger models. Architectural efficiency, like the innovations introduced by DeepSeek, has started to close the gap between size and capability. And post-training techniques, especially instruction tuning and reinforcement learning from human or AI feedback (RLHF/RLAIF), have made models more aligned, controllable, and responsive in practice.</p><p>The more fundamental shift, however, is happening at inference time. Since late 2024, with models like OpenAI’s o1, we’ve entered a new phase where models can trade compute for reasoning <em>on demand</em>. Rather than relying solely on what was baked in during training, they can now “think harder” at runtime, running more internal steps, exploring alternative answers, or chaining thoughts before responding. This opens up new capability ceilings, but also introduces new cost dynamics.</p><p>These varied improvement strategies have led to a clear divergence among AI labs and models, a rapid expansion in model choice, and in some cases, an explosion in model usage costs.</p><h2 class="wp-block-heading"><strong>The Modern Cost Explosion: How Inference Scaling Changed the Game</strong></h2><p>Inference-time compute scaling has introduced a new dynamic in LLM system design: We’ve gone from a single lever model size, to at least four distinct ways to trade cost for capability at runtime. The result is a widening gap in inference cost across models and use cases, sometimes by factors of 10,000x or more.</p><p><strong>Larger models (size scaling): </strong>The most obvious lever is sheer model size. Frontier LLMs, like GPT-4.5, often built with mixture of experts (MoE) architectures, can have input token costs 750 times higher than streamlined models like Gemini Flash-Lite. Larger parameter counts mean more compute per token, especially when multiple experts are active per query.</p><p><strong>Series scaling (“thinking tokens”): </strong>Newer “reasoning” LLMs perform more internal computational steps, or a longer chain of thought, before producing their final answer. For example, OpenAI’s o1 used ~30x more compute than GPT-4o on average, and often 5x more output tokens per task. Agentic systems introduce an additional method of series scaling and an extra layer of cost multiplication. As these agents think, plan, act, reassess, plan, act, and so on, they often make many LLM steps in a loop, each incurring additional cost.</p><p><strong>Parallel scaling: </strong>Here, the system runs multiple model instances on the same task and then automatically selects the best output via automated methods, such as majority voting (which assumes the most common answer is likely correct) or self-confidence scores (where the model output claiming the highest confidence in its response is taken as the best). The o3-pro model likely runs 5–10x parallel instances over o3. This multiplies the cost by the number of parallel attempts (with some nuance).</p><p><strong>Input context scaling: </strong>In RAG pipelines, the number of retrieved chunks and their size directly influence input token costs and the LLM’s ability to synthesize a good answer. More context can often improve results, but this comes at a higher cost and potential latency. Context isn’t free; it’s another dimension of scaling that developers must budget for.</p><p>Taken together, these four factors represent a fundamental shift in how model cost scales. For developers designing systems for high-value problems, <strong>10,000x to 1,000,000x differences in API costs to solve a problem based on architectural choices are now realistic possibilities</strong>. Reasoning LLMs, although only prominent for about nine months, reversed the trend of declining access costs to the very best models. This transforms the decision from “Which LLM should I use?” to include “How much reasoning do I <em>want to pay for</em>?”</p><p>This shift changes how we think about selection. Choosing an LLM is no longer about chasing the highest benchmark score; it’s about finding the balance point where capability, latency, and cost align with your use case.</p><h2 class="wp-block-heading"><strong>Core Model Selection Criteria</strong></h2><p>When choosing a model we find it is important to first clearly identify your use case and the minimum core AI capabilities and attributes needed to deliver it.</p><p>A common first step is to take a look at standard benchmark scores (for example LiveBench, MMLU-Pro, SWE-Bench). These benchmarks are a useful starting point, but some models are tuned on benchmark data, and real-world performance on tasks that are actually relevant to you will often vary. Filtering benchmark tests and scores by your industry and task category is a valuable step here. An LLM optimized for software development might perform poorly in creative writing or vice versa. The match between a model’s training focus and your application domain can outweigh general-purpose benchmarks.</p><p>Leaderboards like <a
href=https://lmarena.ai/leaderboard target=_blank rel="noreferrer noopener">LMArena</a> and <a
href=https://artificialanalysis.ai/ target=_blank rel="noreferrer noopener">Artificial Analysis</a> offer broader human‑preference comparisons but still don’t replace custom real-world testing. It helps to have a set of your own example questions or tasks at hand to test out a new model for yourself and see how it performs. This should include a mix of easy tasks to establish a baseline and tough edge cases where it&#8217;s easy for a model to make mistakes.</p><p>As you move beyond ad hoc testing, for any serious development effort, <strong>custom evaluations are non-negotiable.</strong> They must be tailored to your use case and the types of problems you solve. This is the only way to truly know if a model, or a change to your system, is genuinely improving things for <em>your</em> users and <em>your</em> specific business goals.</p><p>Here are some core factors we consider:</p><p><strong>Multimodality</strong> is emerging as a major differentiator. Models like GPT-4o and Gemini can handle not just text but also images, audio, and in some cases video, unlocking applications that pure text models can’t support.</p><p><strong>Context window</strong> and effective <strong>context window utilization</strong> are also key: How many tokens or documents can the model process and how much of that advertised context window can the LLM <em>actually use</em> effectively without performance degradation relative to tasks that use less context?</p><p><strong>Latency</strong> is especially critical for interactive applications. In general, smaller or cheaper models tend to respond faster, while reasoning-heavy models introduce delays due to deeper internal computation.</p><p><strong>Reasoning </strong>is the ability to scale inference-time compute and perform multistep problem-solving, planning, or deep analysis.</p><p><strong>Privacy and security </strong>are often key considerations here. For example, if you want to keep your intellectual property private, you must use a model that won&#8217;t train on your inputs, which often points toward self-hosted or specific enterprise-grade API solutions.</p><p><strong>Trustworthiness</strong> is also becoming important and can come down to the reputation and track record of the AI lab. A model that produces erratic, biased, or reputationally damaging outputs is a liability, regardless of its benchmark scores. For instance, Grok has had well-publicized issues with its alignment. Even if such issues are supposedly fixed, it creates a lingering question of trust: How can one be sure it won&#8217;t behave similarly in the future?</p><p>Additionally, the <strong>knowledge cutoff date</strong> also matters if it is to be used in a fast-moving field.</p><p>After working out if a model meets your minimum capability, the next decision is often on optimizing trade-offs among cost, reliability, security, and latency. A key rule of thumb we find useful here: If the reliability gain from a more expensive model or more inference time saves more of your or your users&#8217; time (valued in terms of pay) than the model costs, going with the larger model is a good decision!</p><h2 class="wp-block-heading"><strong>The Pros and Cons of Open-Weight and Closed-API LLMs</strong></h2><p>The rise of increasingly competitive open-weight LLMs, such as Meta’s Llama series, Mistral, DeepSeek, Gemma, Qwen, and now OpenAI’s GPT-OSS has added a critical dimension to the model selection landscape. Momentum behind this open ecosystem surged with the release of DeepSeek’s R1 reasoning model, competitive with OpenAI’s o1 but priced at roughly 30x lower API <strong>costs</strong>. This sparked debate around efficiency versus scale and intensified the broader AI rivalry between China and the US. Reactions ranged from “OpenAI and Nvidia are obsolete” to “DeepSeek’s costs must be fabricated,” but regardless of hype, the release was a milestone. It showed that architectural innovation, not just scale, could deliver frontier-level performance with far greater cost efficiency.</p><p>This open-model offensive has continued with strong contributions from other Chinese labs like Alibaba (Qwen), Kimi, and Tencent (Hunyuan), and has put competitive pressure on Meta after its open-weight Llama models fell behind. China’s recent leadership in open-weight LLMs has raised new security/IP issues with some US- and European-based organizations, though we note accessing these model weights and running the model on your own infrastructure doesn’t require sending data to China.</p><p>This brings us back to the pros and cons of open weights. While closed-API LLMs still lead at the frontier of capability, the primary advantage of open-weight models is quick and affordable local testing, unparalleled flexibility, and increased data security when run internally. Organizations can also perform <strong>full fine-tuning</strong>, adapting the model’s core weights and behaviors to their specific domain, language, and tasks. Open models also provide <strong>stability and predictability</strong>—you control the version you deploy, insulating your production systems from unexpected changes or degradations that can sometimes occur with unannounced updates to proprietary API-based models.</p><p>Public closed-model APIs from major providers benefit from immense economies of scale and highly optimized GPU utilization by batching requests from thousands of users, an efficiency that is difficult for a single organization to replicate. This often means that using a closed-source API can be cheaper per inference than self-hosting an open model. Security and compliance are also more nuanced than they first appear. While some organizations must use self-hosted models to simplify compliance with regulations like GDPR by keeping data entirely within their own perimeter, this places the entire burden of securing the infrastructure on the internal team—a complex and expensive undertaking. Top API providers also often offer dedicated instances, private cloud endpoints, and contractual agreements that can guarantee data residency, zero-logging, and meet stringent regulatory standards. The choice, therefore, is not a simple open-versus-closed binary.</p><p>The boundary between open and closed models is also becoming increasingly blurred. Open-weight models are increasingly offered via API by third-party LLM inference platforms, combining the flexibility of open models with the simplicity of hosted access. This hybrid approach often strikes a practical balance between control and operational complexity.</p><h2 class="wp-block-heading"><strong>Leading Closed LLMs</strong></h2><p>Below, we present some key costs and metrics for leading closed-source models available via API. Many of these models have additional complexity and varied pricing including options for fast modes, thinking modes, context caching, and longer context.</p><p>We present the latest LiveBench benchmark score for each model as one measure for comparison. LiveBench is a continuously updated benchmark designed to provide a &#8220;contamination-free&#8221; evaluation of large language models by regularly releasing new questions with objective, verifiable answers. It scores models out of 100 on a diverse set of challenging tasks, with a significant focus on capabilities like reasoning, coding, and data analysis. The similar LiveBench scores between GPT-4.5 and 2.5 Flash-Lite, despite 750x input token cost variation, highlights both that smaller models are now very capable but also that not all capabilities are captured in a single benchmark!</p><figure
class="wp-block-image size-full is-resized"><img
fetchpriority=high decoding=async width=1735 height=1650 src=https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1.png alt="AI model pricing and specifications comparison" class=wp-image-17340 style=width:619px;height:auto srcset="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1.png 1735w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1-300x285.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1-1600x1522.png 1600w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1-768x730.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing1-1536x1461.png 1536w" sizes="(min-width: 1024px) 800px, 100vw"><figcaption
class=wp-element-caption><em>Source: Towards AI, Company Reports, <a
href=https://livebench.ai/ target=_blank rel="noreferrer noopener">LiveBench AI</a>&nbsp;</em><br></figcaption></figure><h2 class="wp-block-heading"><strong>Leading open-weight LLMs</strong></h2><p>Below, we also present key costs, the LiveBench benchmark score, and context length for leading open-weight models available via API. We compare hosted versions of these models for easy comparison. Different API providers may choose to host open-weight models with different levels of quantization, different context lengths, and different pricing, so performance can vary between providers.</p><figure
class="wp-block-image size-full is-resized"><img
decoding=async width=468 height=520 src=https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing-and-Specifications.png alt="AI model pricing and specifications 2" class=wp-image-17338 style=width:546px;height:auto srcset="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing-and-Specifications.png 468w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2025/08/AI-Model-Pricing-and-Specifications-270x300.png 270w" sizes="(min-width: 1024px) 800px, 100vw"><figcaption
class=wp-element-caption><em>Source: Towards AI, Company Reports, <a
href=https://livebench.ai/ target=_blank rel="noreferrer noopener">LiveBench AI</a></em></figcaption></figure><p>Whether hosted or self-deployed, selecting a model only solves part of the problem. In practice, most of the complexity and opportunity lies in how that model is used: how it’s prompted, extended, fine-tuned, or embedded within a broader workflow. These system-level decisions often have a greater impact on performance and cost than the model choice itself.</p><h2 class="wp-block-heading"><strong>A Practical Guide to Designing an LLM System</strong></h2><p>Simply picking the biggest or newest LLM is rarely the optimal strategy. A more effective approach starts with a deep understanding of the developer’s toolkit: knowing which technique to apply to which problem to achieve the desired capability and reliability without unnecessary cost. This is all part of the constant “<strong>march of nines” as you develop LLM systems modularly to solve for more reliability and capability.</strong> There is a need to prioritize the easiest wins that deliver tangible value before investing in further incremental and often costly accuracy improvements. The reality will always vary on a case-by-case basis, but here is a quick guide to navigating this process.</p><h3 class="wp-block-heading"><strong>Step 1: Open Versus Closed?</strong></h3><p>This is often your first decision.</p><ul
class=wp-block-list>
<li><strong>Go with a closed-API model (e.g., from OpenAI, Google, Anthropic) if:</strong> Your priority is accessing the absolute state-of-the-art models with maximum simplicity.</li><li><strong>Go with an open-weight model (e.g., Llama, Mistral, Qwen, DeepSeek) if:</strong><ul
class=wp-block-list>
<li><strong>Data security and compliance are paramount:</strong> If you need to guarantee that sensitive data never leaves your own infrastructure.</li><li><strong>You need deep customization and control:</strong> If your goal is to fine-tune a model on proprietary data and to create a specialized expert that you control completely.</li></ul>
</li></ul><p>If you went open, what can you <em>realistically</em> run? Your own GPU infrastructure is a hard constraint. Assess your cluster size and memory to determine if you can efficiently run a large, leading 1&nbsp;trillion+&nbsp;parameter MoE model, such as Kimi K2, or if you are better served by a medium-size&nbsp;model such as Gemma 3 27B or a much smaller model&nbsp;like Gemma 3n that can even run on mobile.</p><h3 class="wp-block-heading"><strong>Step 2: Gauging the Need for Reasoning</strong></h3><p>Does your task require the model to simply blast out a response, or does it need to <em>think</em> first?</p><ul
class=wp-block-list>
<li><strong>Reasoning:</strong> For tasks that involve complex, multistep problem-solving, brainstorming, strategic planning, intricate code generation, or deep analysis, you need a dedicated reasoning model such as o3, Gemini&nbsp;2.5 Pro, DeepSeek&nbsp;R1, or Claude&nbsp;4. In some cases these models can be used in high-reasoning mode, which encourages the model to think for longer before responding.</li><li><strong>No reasoning:</strong> For straightforward tasks like simple Q&amp;A, summarization of a single document, data extraction, or classification, a powerful reasoning model is overkill.</li><li><strong>The middle ground:</strong> For tasks requiring moderate reasoning, such as generating a structured report from a few data points or performing basic data analysis at scale, a “mini” reasoning model, like OpenAI’s o4-mini or Gemini Flash 2.5, offers a balance of capability and cost.</li></ul><h3 class="wp-block-heading"><strong>Step 3: Pinpointing Key Model Attributes</strong></h3><p>Beyond general intelligence and reasoning, modern LLMs are specialists. Your choice should be guided by the specific attributes and “superpowers” your application needs.</p><ul
class=wp-block-list>
<li><strong>Prioritize accuracy over cost</strong> for high-value tasks where mistakes are costly or where a human expert’s time is being saved. o3-pro is a standout model here and it can even be used as a fact checker to meticulously check the details of an earlier LLM output.</li><li><strong>Prioritize speed and cost over accuracy:</strong> For user-facing, real-time applications like chatbots or high-volume, low-value tasks like simple data categorization, latency and cost are paramount. Choose a hyper-efficient “flash” or “mini” model such as Gemini 2.5 Flash-Lite. Qwen3-235B models can also be a great option here but are too complex to inference yourself.</li><li><strong>Do you need a deep, long-context researcher?</strong> For tasks that require synthesizing information from massive documents, entire codebases, or extensive legal contracts, a model with a vast and highly effective context window is crucial. <strong>Gemini 2.5 Pro</strong> excels here.</li><li><strong>Is multimodality essential?</strong> If your application needs to understand or generate images, process audio in real time, or analyze video, your choice narrows to models like <strong>GPT-4o</strong> or the <strong>Gemini</strong> family. For one-shot YouTube video processing, Gemini is the standout.</li><li><strong>Is it a code-specific task?</strong> While many models can code, some are explicitly tuned for it. In the open world, Codestral and Gemma do a decent job. But Claude has won hearts and minds, at least for now.</li><li><strong>Do you need live, agentic web search?</strong> For answering questions about current events or topics beyond the model’s knowledge cutoff, consider a model with a built-in, reliable web search, such as <strong>o3.</strong></li><li>Do you need complex <strong>dialogue and emotional nuance?</strong> GPT-4.5, Kimi K2, Claude Opus 4.0, or Grok 4 do a great job.</li></ul><h3 class="wp-block-heading"><strong>Step 4: Prompting, Then RAG, Then Evaluation</strong></h3><p>Before you dive into more complex and costly development, always see how far you can get with the simplest techniques. This is a path of escalating complexity. Model choice for RAG pipelines is often centered around latency for end users, but recently more complex agentic RAG workflows or long-context RAG tasks require reasoning models or longer context capabilities.</p><ol
class=wp-block-list>
<li><strong>Prompt engineering first:</strong> Your first step is always to maximize the model’s inherent capabilities through clear, well-structured prompting. Often, a better prompt with a more capable model is all you need.</li><li><strong>Move to retrieval-augmented generation (RAG):</strong> If your model’s limitation is a lack of specific, private, or up-to-date <em>knowledge</em>, RAG is the next logical step. This is the best approach for reducing hallucinations, providing answers based on proprietary documents, and ensuring responses are current. However, RAG is not a panacea. Its effectiveness is entirely dependent on the quality and freshness of your dataset, and building a retrieval system that consistently finds and uses the <em>most</em> relevant information is a significant engineering challenge. RAG also comes with many associated decisions, such as the quantity of data to retrieve and feed into the model’s context window, and just how much use you make of long-context capabilities and context caching.</li><li><strong>Iterate with advanced RAG:</strong> To push performance, you will need to implement more advanced techniques like hybrid search (combining keyword and vector search), re-ranking retrieved results for relevance, and query transformation.</li><li><strong>Build custom evaluation</strong>: Ensure iterations on your system design, additions of new advanced RAG techniques, or updates to the latest model are always moving progress forward on your key metrics!</li></ol><h3 class="wp-block-heading"><strong>Step 5: Fine-Tune or Distill for Deep Specialization</strong></h3><p>If the model’s core <em>behavior</em>—not its knowledge—is still the problem, then it’s time to consider fine-tuning. Fine-tuning is a significant undertaking that requires a high-quality dataset, engineering effort, and computational resources. However, it can enable a smaller, cheaper open-weight model to outperform a massive generalist model on a specific, narrow task, making it a powerful tool for optimization and specialization.</p><ul
class=wp-block-list>
<li><strong>Fine-tuning is for changing behavior, not adding knowledge.</strong> Use it to teach a model a specific skill, style, or format. For example:<ul
class=wp-block-list>
<li>To reliably output data in a complex, structured format like specific JSON or XML schemas.</li><li>To master the unique vocabulary and nuances of a highly specialized domain (e.g., legal, medical).</li><li>Some closed-source models are available for fine-tuning via API such as Gemini 2.5 Flash and various OpenAI models. Larger models are normally not available.</li><li><strong>In open-weight models, </strong>Llama 3.3 70B and Qwen 70B are fine-tuning staples. The process is more complex to fine-tune an open-weight model yourself.</li></ul>
</li><li>Model <strong>distillation</strong> can also serve as a production-focused optimization step. In its simplest form, this consists of generating synthetic data from larger models to create fine-tuning datasets to improve the capabilities of smaller models.</li><li><strong>Reinforcement fine-tuning (RFT) for problem-solving accuracy</strong><br>Instead of just imitating correct answers, the model learns by trial, error, and correction. It is rewarded for getting answers right and penalized for getting them wrong.<ul
class=wp-block-list>
<li><strong>Use RFT to:</strong> Create a true “expert model” that excels at complex tasks with objectively correct outcomes.</li><li><strong>The advantage:</strong> RFT is incredibly data-efficient, often requiring only a few dozen high-quality examples to achieve significant performance gains.</li><li><strong>The catch:</strong> RFT requires a reliable, automated “grader” to provide the reward signal. Designing this grader is a critical engineering challenge.</li></ul>
</li></ul><h3 class="wp-block-heading"><strong>Step 6: Orchestrated Workflows Versus Autonomous Agents</strong></h3><p>The critical decision here is how much freedom to grant. Autonomous agents are also more likely to need more expensive reasoning models with greater levels of inference scaling. Parallel inference scaling methods with multiple agents are also beginning to deliver great results. Small errors can accumulate and multiply during many successive agentic steps so the investment in a stronger more capable model can make all the difference in building a usable product.</p><ul
class=wp-block-list>
<li><strong>Choose an orchestrated workflow for predictable tasks</strong> <br>You design a specific, often linear, sequence of steps, and the LLM acts as a powerful component at one or more of those steps.<ul
class=wp-block-list>
<li><strong>Use when:</strong> You are automating a known, repeatable business process (e.g., processing a customer support ticket, generating a monthly financial summary). The goal is reliability, predictability, and control.</li><li><strong>Benefit:</strong> You maintain complete control over the process, ensuring consistency and managing costs effectively because the number and type of LLM calls are predefined.</li></ul>
</li><li><strong>Build hybrid pipelines:</strong> Often, the best results will come from combining many LLMs, open and closed, within a pipeline.<ul
class=wp-block-list>
<li>This means using different LLMs for different stages of a workflow: a fast, cheap LLM for initial query routing; a specialized LLM for a specific subtask; a powerful reasoning LLM for complex planning; and perhaps another LLM for verification or refinement.</li><li>At Towards AI, we often have 2-3 different LLMs from different companies in an LLM pipeline.</li></ul>
</li><li><strong>Choose an autonomous agent for open-ended problems.</strong> You give the LLM a high-level goal, a set of tools (e.g., APIs, databases, code interpreters), and the autonomy to figure out the steps to achieve that goal.<ul
class=wp-block-list>
<li><strong>Use when:</strong> The path to the solution is unknown and requires dynamic problem-solving, exploration, or research (e.g., debugging a complex software issue, performing deep market analysis, planning a multistage project).</li><li><strong>The critical risk—runaway costs:</strong> An agent that gets stuck in a loop, makes poor decisions, or explores inefficient paths can rapidly accumulate enormous API costs. <strong>Implementing strict guardrails is critical:</strong><ul
class=wp-block-list>
<li><strong>Budget limits:</strong> Set hard caps on the cost per task.</li><li><strong>Step counters:</strong> Limit the total number of “thoughts” or “actions” an agent can take.</li><li><strong>Human-in-the-loop:</strong> Require human approval for potentially expensive or irreversible actions.</li></ul>
</li><li>Gemini 2.5 Pro and o3 are our favourite closed-API models for agent pipelines, while in open-weight models we like Kimi K2.</li></ul>
</li></ul><p>Working through these steps helps translate a vague problem into a concrete implementation plan, one that’s grounded in clear trade-offs and tailored to your needs. This structured approach often yields systems that are not only more capable and reliable but also far more effective for specific tasks than a general-purpose chatbot ever could be.</p><h2 class="wp-block-heading"><strong>Conclusion</strong></h2><p>The open-versus-closed race gives us rapid access to strong LLMs but also creates complexity. Selecting and deploying them demands both engineering discipline and economic clarity.</p><p>Developing in the LLM ecosystem demands a new level of engineering discipline and keen economic awareness. No single LLM is a cure-all. A practical, evolving toolkit is essential, but knowing which tool to pull out for which job is the real art. The challenge isn’t just picking a model from a list; it’s about architecting a solution. This requires a systematic approach, moving from high-level strategic decisions about data and security down to the granular, technical choices of development and implementation.</p><p>The success of specialized “LLM wrapper” applications like Anyscale/Cursor for coding or Perplexity for search, some of which are now valued at over $10 billion, underscores the immense value in this tailored approach. These applications aren’t just thin wrappers; they are sophisticated systems that leverage foundation LLMs but add significant value through custom workflows, fine-tuning, data integration, and user experience design.</p><p>Ultimately, success hinges on informed pragmatism. Developers and organizations need a sharp understanding of their problem space and a firm grasp of how cost scales across model choice, series and parallel reasoning, context usage, and agentic behavior. Above all, custom evaluation is non-negotiable because your use case, not a benchmark, is the only standard that truly matters.</p></div><div
class=postContent-end><div
class=radar-post-page-meta >
Post topics: <a
href=https://www.oreilly.com/radar/topics/ai-ml/ title="AI &amp; ML">AI &amp; ML</a></div><div
class=radar-post-page-meta >
Post tags: <a
href=https://www.oreilly.com/radar/tag/research/ title=Research>Research</a></div></div></section></div></div><div
id=bottomModules class=bottomModules></div></main><footer
id=footer class=footer><div
class=content><div
class=footer-social><p>Follow us</p><a
href=https://www.linkedin.com/company/oreilly-media target=_blank><svg
xmlns=http://www.w3.org/2000/svg width=24 height=24 viewBox="0 0 24 24" fill=none><title>linkedin logo</title><g
clip-path=url(#clip0_1065_834)><path
d="M20.447 20.452H16.893V14.883C16.893 13.555 16.866 11.846 15.041 11.846C13.188 11.846 12.905 13.291 12.905 14.785V20.452H9.351V9H12.765V10.561H12.811C13.288 9.661 14.448 8.711 16.181 8.711C19.782 8.711 20.448 11.081 20.448 14.166L20.447 20.452ZM5.337 7.433C4.193 7.433 3.274 6.507 3.274 5.368C3.274 4.23 4.194 3.305 5.337 3.305C6.477 3.305 7.401 4.23 7.401 5.368C7.401 6.507 6.476 7.433 5.337 7.433ZM7.119 20.452H3.555V9H7.119V20.452ZM22.225 0H1.771C0.792 0 0 0.774 0 1.729V22.271C0 23.227 0.792 24 1.771 24H22.222C23.2 24 24 23.227 24 22.271V1.729C24 0.774 23.2 0 22.222 0H22.225Z" fill=#444444 /></g><defs><clipPath
id="clip0_1065_834"><rect
width=24 height=24 fill=white /></clipPath></defs></svg></a><a
href=https://www.youtube.com/user/OreillyMedia target=_blank><svg
xmlns=http://www.w3.org/2000/svg width=24 height=24 viewBox="0 0 24 24" fill=none><title>youtube logo</title><path
d="M23.495 6.20498C23.356 5.70674 23.0907 5.2528 22.725 4.88703C22.3592 4.52126 21.9052 4.25603 21.407 4.11698C19.537 3.61598 12.011 3.61598 12.011 3.61598C12.011 3.61598 4.50401 3.60598 2.61501 4.11698C2.11677 4.25603 1.66283 4.52126 1.29706 4.88703C0.931287 5.2528 0.666058 5.70674 0.527007 6.20498C0.172528 8.11949 -0.0022322 10.0629 0.00500725 12.01C-0.000863617 13.9497 0.173891 15.8857 0.527007 17.793C0.666058 18.2912 0.931287 18.7452 1.29706 19.1109C1.66283 19.4767 2.11677 19.7419 2.61501 19.881C4.48301 20.383 12.011 20.383 12.011 20.383C12.011 20.383 19.517 20.383 21.407 19.881C21.9052 19.7419 22.3592 19.4767 22.725 19.1109C23.0907 18.7452 23.356 18.2912 23.495 17.793C23.8407 15.885 24.0081 13.949 23.995 12.01C24.0095 10.0636 23.8421 8.12018 23.495 6.20498ZM9.60901 15.601V8.40798L15.873 12.01L9.60901 15.601Z" fill=#444444 /></svg></a></div><div
class=footer-main aria-label="company info"><div
class=footer-mainLeft><div
class=footer-approach><h2 class="footer-header"><a
href=https://www.oreilly.com/about/ >About O&rsquo;Reilly</a></h2><ul
class=footer-links>
<li><a
href=https://www.oreilly.com/work-with-us.html>Teach/Write/Train</a></li>
<li><a
href=https://www.oreilly.com/careers/ >Careers</a></li>
<li><a
href=https://www.oreilly.com/press/ >O&rsquo;Reilly News</a></li>
<li><a
href=https://www.oreilly.com/press/media-coverage.html>Media Coverage</a></li>
<li><a
href=https://www.oreilly.com/partner/signup.csp>Community Partners</a></li>
<li><a
href=https://www.oreilly.com/affiliates/ >Affiliate Program</a></li>
<li><a
href=https://www.oreilly.com/online-learning/rfp.html>Submit an RFP</a></li>
<li><a
href=https://www.oreilly.com/diversity/ >Diversity</a></li>
<li><a
href=https://www.oreilly.com/content-marketing-solutions.html id=footerSponsorshipLink>Content Sponsorship</a></li></ul></div><div
class=footer-contact><h2 class="footer-header"><a
href=https://www.oreilly.com/online-learning/support/ >Support</a></h2><ul
class=footer-links>
<li><a
href=https://www.oreilly.com/about/contact.html>Contact Us</a></li>
<li><a
href=https://www.oreilly.com/emails/newsletters/ >Newsletters</a></li>
<li><a
href=https://www.oreilly.com/privacy.html>Privacy Policy</a></li>
<li><a
href=https://www.oreilly.com/about/oreilly-approach-to-generative-ai.html>AI Policy</a></li></ul></div><div
class=footer-international><h2 class="footer-header">International</h2><ul
class=footer-links>
<li><a
href=https://www.oreilly.com/online-learning/anz.html>Australia &amp; New Zealand</a></li>
<li><a
href=https://www.oreilly.co.jp/index.shtml>Japan</a></li></ul></div></div><div
class=footer-mainRight><div
class=footer-download id=download-info><h2 class="footer-header">Download the O&rsquo;Reilly App</h2><p>Take O&rsquo;Reilly with you and learn anywhere, anytime on your phone and tablet.</p><div
class=footer-downloadLinks>
<a
href=https://itunes.apple.com/us/app/safari-to-go/id881697395><img
src=https://cdn.oreillystatic.com/oreilly/images/app-store-logo.png alt="Apple app store"></a>
<a
href="https://play.google.com/store/apps/details?id=com.safariflow.queue"><img
src=https://cdn.oreillystatic.com/oreilly/images/google-play-logo.png  alt="Google play store"></a></div></div><div
class=footer-download id=tv-info><h2 class="footer-header">Watch on Your Big Screen</h2><p>View all O&rsquo;Reilly videos, virtual conferences, and live events on your home TV.</p><div
class=footer-downloadLinks>
<a
href=https://channelstore.roku.com/details/c9d25fa651f0ad84e484b0dfd4b20172:856a240ad268961983e91ae52c1e1e5c/oreilly><img
src=https://cdn.oreillystatic.com/oreilly/images/roku-tv-logo.png alt="Roku Players and TVs"></a>
<a
href="https://www.amazon.com/OReilly-Media-Inc/dp/B087YYHL5C/ref=sr_1_2?dchild=1&keywords=oreilly&qid=1604964116&s=mobile-apps&sr=1-2"><img
src=https://cdn.oreillystatic.com/oreilly/images/amazon-appstore-logo.png  alt="Amazon appstore"></a></div></div></div></div><div
class=footer-subfooter>
<a
class=footer-subfooterLogo href=https://www.oreilly.com title="home page" aria-current=page>
<img
id=footer-subfooterLogo
src=https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg
srcset="https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red_@2x.png 2x"
alt="O'Reilly home">
</a><div
class=footer-donotsell id=donotsell-info><h2 class="footer-header"><a
href="https://www.oreilly.com/privacy.html?donotsell=show">Do not sell or share my personal information</a>.</h2></div><div><p>&copy; 2025, O&rsquo;Reilly Media, Inc.  All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.</p><p><a
href=https://www.oreilly.com/terms/ >Terms of Service</a> &bull; <a
href=https://www.oreilly.com/privacy.html>Privacy Policy</a> &bull; <a
href=https://www.oreilly.com/about/editorial_independence.html>Editorial Independence</a><span
class=transparencyStatement style=display:none;> &bull; <a
href=https://www.oreilly.com/modern-slavery-act-transparency-statement.html>Modern Slavery Act Statement</a></span></p></div></div></div></footer> <script type=speculationrules>{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/radar\/*"},{"not":{"href_matches":["\/radar\/wp-*.php","\/radar\/wp-admin\/*","\/radar\/wp-content\/uploads\/sites\/3\/*","\/radar\/wp-content\/*","\/radar\/wp-content\/plugins\/*","\/radar\/wp-content\/themes\/signal\/*","\/radar\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}</script> <script id=feed-loader-js-extra>var feed_ajax = {"ajaxurl":"https:\/\/www.oreilly.com\/radar\/wp-admin\/admin-ajax.php"};</script> <script src=https://www.oreilly.com/radar/wp-content/cache/minify/3/afccc.js></script>  <script src=https://cdn.oreillystatic.com/assets/js/skills-nav.js></script> <script>// Handle the reading mode toggle
const themeToggleBtn = document.getElementById('themeToggle');
let savedTheme = localStorage.getItem('theme');
const prefersDarkTheme = window.matchMedia('(prefers-color-scheme: dark)').matches;
const prefersLightTheme = window.matchMedia('(prefers-color-scheme: light)').matches;
const theme = savedTheme || (prefersDarkTheme ? 'dark' : (prefersLightTheme ? 'light' : 'dark'));

document.documentElement.setAttribute('data-theme', theme);
themeToggleBtn.setAttribute('aria-pressed', theme === 'light');

document.addEventListener("DOMContentLoaded", () => {
  themeToggleBtn.addEventListener('click', () => {
    const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
    const newTheme = isDark ? 'light' : 'dark';
    document.documentElement.setAttribute('data-theme', newTheme);
    localStorage.setItem('theme', newTheme);
    themeToggleBtn.setAttribute('aria-pressed', newTheme === 'light');


    if (typeof dataLayer !== "undefined" && Array.isArray(dataLayer)) {
      dataLayer.push({
        'event': "eventTracker",
        'eventCat': "radar",
        'eventAct': "reading mode",
        'eventLbl': newTheme,
        'eventVal': 0,
        'nonInteraction': 0
      });
    } else {
      console.warn("dataLayer is not defined. Reading mode event not tracked.");
    }
  });

  // Enable transitions only after initial setup
  requestAnimationFrame(() => {
    document.documentElement.classList.add('enableTransitions');
  });
});


window.addEventListener("scroll", function () {
  document.body.classList.toggle("scrolled", window.scrollY > 50);
});

jQuery(function() {
  //Toggle isActive and mobileHidden classes for mobileNavButton
  jQuery('nav #mobileNavButton').on('click', function() {
    var expanded = jQuery(this).attr('aria-expanded') === 'true' || false;
    jQuery(this).attr('aria-expanded', !expanded);
    jQuery(this).toggleClass("isActive");
    jQuery(this).prev().toggleClass("mobileHidden");
  });

  //Toggle isFocused class for keyboard navigation of submenus
  jQuery('nav #menuList .menuList-subItem a').each(function(navItem) {
    jQuery(this).on('focus', function() {
      jQuery(this).parents('.menuList-itemWithSub, .menuList-subList').toggleClass('isFocused');
    });
    jQuery(this).on('blur', function() {
      jQuery(this).parents('.menuList-itemWithSub, .menuList-subList').toggleClass('isFocused');
    });
  });

  //Toggle mobileHidden class accordian elements
  jQuery('.mobileAccordian').each(function() {
    var $btn = jQuery(this).find('button');
    var $target =  jQuery(this).next();
    $btn.on('click', function() {
      var expanded = $btn.attr('aria-expanded') === 'true' || false;

      $btn.attr('aria-expanded', !expanded);
      $target.toggleClass("mobileHidden");  
    });
  });

  //Search platform form action
  function searchSubmit(e) {
    e.preventDefault();
    sParameter = searchForm.search.value;
    sParameter = encodeURIComponent(sParameter.trim());
    sURL = searchForm.action + '?query=' + sParameter;
    window.location = sURL;

    //GA event for search
    dataLayer.push({
      'event': 'eventTracker',
      'eventCat':'site search',
      'eventAct':'search box',
      'eventLbl':'explore our content',
      'eventVal':0, 
      'nonInteraction': 0,
    });
  }
  const searchForm = document.getElementById('js-searchForm');
  searchForm.addEventListener('submit', searchSubmit);

  //Search button action
  function showNavSearch(e) {
    jQuery('.menuList-item-search').addClass('overlay');
    jQuery('.menuList-item-search input#search').focus();
  }
  const searchButton = document.getElementById('js-searchButton');
  searchButton.addEventListener('click', showNavSearch);

  //Close search button action
  function hideNavSearch(e) {
    jQuery('.menuList-item-search').removeClass('overlay');
  }
  const searchCloseButton = document.getElementById('js-searchCloseButton');
  searchCloseButton.addEventListener('click', hideNavSearch);
});</script> <script id=MathJax-script>var math = document.getElementsByClassName('math-tex');
    if (math.length > 0) includeMathJax();
    function includeMathJax() {
      var head = document.getElementsByTagName('head')[0];
      var script = document.createElement('script');
      script.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
      script.type = 'text/javascript';
      script.async = 'async';
      head.appendChild(script)
    }</script> <script type="text/javascript" nonce="7f75382e634a24127dde6b59ed835971" src="/JY114ZI2w/G9wF/KMO6w/9EbiGtVLzwzmkSXODa/BUYyEwh-WAY/XBFmMCw/kV1wB"></script><link rel="stylesheet" type="text/css" nonce="7f75382e634a24127dde6b59ed835971" href="/JY114ZI2w/G9wF/KMO6w/LpbiJi/Oz4VEwh-WAY/NSRLeBE/mehtZ"><script nonce="7f75382e634a24127dde6b59ed835971" src="/JY114ZI2w/G9wF/KMO6w/LpbiJi/Oz4VEwh-WAY/KBt5cAh/PV0gp" async defer></script><div id="sec-overlay" style="display:none;"><div id="sec-container"></div></div></body></html>